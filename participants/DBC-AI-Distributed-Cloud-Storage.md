# DBC-AI-Distributed-Cloud-Storage

Before submitting a PR containing your team's project information:
- Make sure you rename this file to contain your project's name
- Respond to add your response in each section below

## (0) Project Name and Team Slack Handles

- Project Name:
    - *DBC-AI-Distributed-Cloud-Storage*

- Team Slack Handles:
    - *deepbrainfeng@gmail.com*

## (1) Brief Project Description

*DBC AI Distribute Cloud Storage is a core component of deep brain chain, DeepBrain Chain is a network of distributed artificial intelligence work force, there are a large number of users in the use of GPU, artificial intelligence AI training, we hope to be able to get the user's data can be stored in the GPU machine not only, also can backup stored in filecoin network, so that users can download data at any time to any GPU machine to calculate.*

## (2) Link to Project UI

*https://github.com/DeepBrainChain/DBC-AI-Distributed-Cloud-Storage.git*

## (3) What does your application/UI do?

*This is a web version of cloud disk, our artificial intelligence users can easily upload data to the network disk, and then users can download the data of the network disk in any gpu machine.*

## (4) If your project is using a curated dataset, which one are you using?

*We didn't use the data.*

## (5) If your project is not using a curated dataset, please tell us a little bit more about your data by answering the questions below.

*We will not collect data. These data belong to our AI users, and we do not have the right to use these data. These data are the data of artificial intelligence developers themselves. We have not done any audit on the data, nor can we know whether the data contains sensitive information. However, these data are all the data of users, and no one else has the right to access the data.*

## (6) How much data are you planning to store to the Filecoin network during the Slingshot competition?

*We hope to upload about 1TB of data. At present, there are more than 15000 artificial intelligence developers and more than 1000 GPUs. The actual user data is much larger than 1TB.*


## (7) How are you structuring the data?

*We will upload the user's original data directly, and the specific data format is determined by the user himself.*

## (8) What pre-processing are you doing before ingesting the data?

*Users upload data directly through the web page, and then we call the API interface of filecoin to transfer the data to the filecoin network. Our own server will record the user's data CID, which is convenient for users to search and download data.*

## (9)  What tech stack will you use to store the data?

*Lotus\ipfs*

## (10) How will you retrieve the data?

*The specific retrieval time is decided by our users themselves. When they need to download the data, they will search the data. The data is saved in filecoin so that it can be downloaded and used at any time*

## (11) Who is the intended user for your application/UI?

*Artificial intelligence program developers, enterprises needing deep learning*

## (12) Do you have any users already or plans to acquire users soon?

*Yes.We currently have more than 15000 AI developer users.*

## (13) What challenges do you anticipate with this project?

*We are worried about whether filecoin can run normally to store or download data. In addition, after the main network is officially launched, we are very concerned about the price of data per hour per TB.*
